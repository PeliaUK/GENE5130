---
title: "Bioinformatics in R WGCNA"
author: "J. Cesar Ignacio Espinoza - Cesar   "
date: 'Week 05: April 15th and 17th 2024'
output:
  pdf_document: default
  html_document:
    highlight: espresso
    theme: cerulean
---

### This class will incorporate a bit of ML.

We will be performing a WGNCA, before proceeding test yourself and make sure you understand what weighted. Gene_network and correlation mean?
#Weighted Correlation Network Analysis (WGCNA)
#Weighted: In networks, "weighted" means assigning numerical values to edges, representing the strength of relationships between connected nodes.

#Gene Network: A gene network is a graphical representation where genes are nodes and interactions between genes (such as co-expression or regulation) are depicted as edges.

#Correlation: Correlation measures the statistical association between two variables, often used in genomics to quantify the similarity of gene expression patterns across samples or conditions.

## The dataset.  
 we will be working with the dataset "	Systems biological assessment of immunity to severe and mild COVID-19 infections" 
 
RNAseq analysis of PBMCs in a group of 17 COVID-19 subjects and 17 healthy controls


```{r setup}
    ### Edit this line so your notebook renders properly
    knitr::opts_knit$set(root.dir = normalizePath("C:/Users/nneka/Documents/KGI_2024/Bioinformatics_in _R/Data_Bio_in_ R_2024")) 
```
We will be using the package called WGCNA, if you do not have it install, please run this cell, once it is installed comment it! #coxpresdb.jp #scale-free very long tail #soft threshold exponential #hard threshold r>XX
```{r}
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("WGCNA")
BiocManager::install("impute")
BiocManager::install("preprocessCore")
```

We now load the libraries
```{r message=FALSE, warning=FALSE, paged.print=FALSE, results="hide"}
# We first need to import the important libnrary for today's class, dplyr
library(WGCNA)
library(dplyr)
library(readr)
library(DESeq2)
library(ggplot2)
```

Load the data (Counts table and metadata from canvas site)

```{r}
### Run this chunk to import the counts table and metadata into your evironment.
counts <- read.csv("~/KGI_2024/BioinformaticsInR2004/DataBioinR2024/GSE152418RawCounts.csv", header = TRUE, row.names = 1)
metadata <- read.csv("~/KGI_2024/BioinformaticsInR2004/DataBioinR2024/GSE152418Metadata.csv", header = TRUE, row.names = 1)
```

### QC:
Here we wanna explore to see if the dataset that we have is good for analysis
We are going to use a function called goodSamplesGenes(). Use the cell below to display the help page of this function, figure out if you can run it

```{r}
#?goodSamplesGenes()#help guide 
#goodSamplesGenes(counts)
goodSamplesGenes(t(counts))#transpose 
gsG <- goodSamplesGenes(t(counts))
 #gsG$allOK
#[1] FALSE

```
```{r}
gsG <- goodSamplesGenes(counts)
```

Subset your data so only the genes that passed the filter are kept

```{r}
?subset
#gsG$goodGenes # some were false hence we subset 
good_counts <- counts[gsG$goodGenes,]
good_counts
```

Another way to detect outliers is to perform hierarchical clustering of all the samples. If you do that you should be able to see if some data points are too far from the rest of the samples.

```{r}
#?hclust#help 
#plot(hclust(dist(t(counts)), method = 'complete'))
temptree <- (hclust(dist(t(counts)), method = 'complete'))
plot(temptree)# based on the result we might have to remove the three samples that are far from each other i.e. outliers ...993, ...995, ..5000
```
```{r}
#?hclust#help 
plot(hclust(dist(t(good_counts)), method = 'complete'))
temptree <- (hclust(dist(t(good_counts)), method = 'complete'))
plot(temptree)
```

Outliers are literally that samples taht are far from each other, we can also look at that by applying dimensionality reduction, one of the most common techniques is PCA. run the cell below to go to the help page for PCA

```{r}
?prcomp
pcomp <- prcomp(good_counts)
pcomp
```

```{r}
#pcomp <- prcomp(t(good_counts))
pcomp$x
```
```{r}
ggplot(data=pcomp$x, aes(x=PC1, y=PC2)) + geom_point() + geom_text(label= rownames(pcomp$x))
  

```

# Filter the data to remove bad samples
**HINT** Use DPlyr

```{r}
really_good_counts <- good_counts %>%
  select(-GSM4614993) %>%
  select(-GSM4614995) %>%
  select(-GSM4615000)
```

#Normalization. 

The 'easiest' way will be to run DESEq2 and use the normalized counts object from DESeq2, Look at your past notes and run it below. You have all you need but you might need to play with the metadata file.
HINT : df[!(row.names(df) %in% row_names_df_to_remove),] ### 

```{r}

#metadata_df <- df[!(row.names(df) %in% row_names_df_to_remove),]
phenotype <- metadata[!row.names(metadata) %in% c("GSM4615000", "GSM4614993", "GSM4614995"),]
### WRITE YOUR CODE HERE, ALSO RENAME THE COLUMNS OF METADATA SO IT IS EASIER TO READ, REMOVE 'DOTS' 
#temp_rename <- rename 
#rename <- dplyr::rename
#phenotype %>%
  #rename(disease_state = disease.state.ch1)
new_phenotype <- phenotype %>%
  rename("days_post_symptom_onset" = "days_post_symptom_onset.ch1") %>%
  rename("disease_state" = "disease.state.ch1") %>%
  rename("gender" = "gender.ch1") %>%
  rename("geohraphical_location" = "geographical.location.ch1") %>%
  rename("severity" ="severity.ch1")
```

```{r}
library(DESeq2) #normalizes by library composition 
dds <- DESeqDataSetFromMatrix(countData = really_good_counts, 
                              colData = new_phenotype,
                              design = ~ 1)

```

 Now remove the genes with counts < 15 in more than 75% of samples (31*0.75 ~ 23)
This number is coming from the WGCNA recommendations
```{r}
counts(dds)
``` 
```{r}
dds75 <- dds[rowSums(counts(dds)) >=23]
``` 

```{r}
dds_norm <- vst(dds75) #varaince transformation  
norm_gene_exp <- t(assay(dds_norm))

```
```{r}
norm_gene_exp
```
#We can finally start with our WGNCA data analysis

First we pick up a soft threshold modify the power vector below 

```{r}
sft <- pickSoftThreshold(norm_gene_exp, 
                  powerVector = c(1:5), 
                  networkType = "signed", 
                  verbose = 2)#how much of output to be seen 
```
```{r}
sft <- pickSoftThreshold(norm_gene_exp, 
                  powerVector = c(1:5), 
                  networkType = "signed", 
                  verbose = 10)
```
You can acess the results with sft$fitIndices. We are going to pick a power that gives us the higherst R2 and the lowest mean K. 

**HINT plot the data!** First plot Power vs r2
```{r}
ggplot(data = sft$fitIndices, aes(x=Power, y=SFT.R.sq)) + geom_point()
```

Then Plot Power vs mean.k
```{r}
ggplot(data = sft$fitIndices, aes(x=Power, y= mean.k)) + geom_point()
```
After you pick up a threshold we are ready to run our data analysis

```{r}
temp_cor <-  cor
cor <- WGCNA::cor
norm_gene_exp[] <- sapply(norm_gene_exp, as.numeric)

bwm <- blockwiseModules(norm_gene_exp, 
                 maxBlockSize = 40000,
                 TOMType = "signed",
#                 power = 15, 
                 mergeCutHeight = 0.2, 
                 numericLabels = FALSE, #if changed to TRUE will give numbers 
                 randomSeed = 1234, 
                 verbose = 2)
```
```{r}
?table
table(bwm$colors)
```
```{r}

```

#explore the bwm object, 
how many modules are there? colour
What us the largest module?
What is the smallest?

```{r}
## RUN THIS AS IS, IT WILL PLOT THE COLORS AND DENDROGRAM

mergedColors = labels2colors(bwm$colors)
plotDendroAndColors(
  bwm$dendrograms[[1]],
  mergedColors[bwm$blockGenes[[1]]],
  "Module colors",
  dendroLabels = FALSE,
  hang = 0.03,
  addGuide = TRUE,
  guideHang = 0.05 )
```
# Now we can correlate our findings with phenotypic states of patients

```{r}
traits <- new_pheno_name %>%
  mutate(disease_state_bin = ifelse(grepl('COVID', disease_state),1,0))

```

```{r}

```


